{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 113 (experiment_utils.py, line 115)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3526\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[1], line 4\u001b[0m\n    from predictorStarter import * # this file contains the import of every dataset, libraries needed and the initial plotting of the data\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32mc:\\Users\\chiod\\Desktop\\MyData\\universita\\tesi\\openSourceImplementations\\cov_pred_finance\\experiments\\predictorStarter.py:17\u001b[1;36m\n\u001b[1;33m    from utils.experiment_utils import *\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32mc:\\Users\\chiod\\Desktop\\MyData\\universita\\tesi\\openSourceImplementations\\cov_pred_finance\\experiments\\utils\\experiment_utils.py:115\u001b[1;36m\u001b[0m\n\u001b[1;33m    return RMSEs\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'for' statement on line 113\n"
     ]
    }
   ],
   "source": [
    "from cvx.covariance.ewma import iterated_ewma, _ewma_cov, _ewma_mean\n",
    "from cvx.covariance.combination import from_sigmas\n",
    "\n",
    "from predictorStarter import * # this file contains the import of every dataset, libraries needed and the initial plotting of the data\n",
    "from predictorsImplementation import * # this file contains the implementation of the predictors ( one function implementation for each predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for plotting and compare inside a unique chart prices and volatilities for ewma predictions\n",
    "\n",
    "def plot_prices_volatilities_for_ewma(stock_prices, real_volatility, real_volatility_startDate, real_volatility_endDate, ewma_volatility, asset_name):\n",
    "    '''\n",
    "    Function to plot prices and volatilities for EWMA\n",
    "    '''\n",
    "    # filter the real volatility between the start and end date\n",
    "    real_volatility_startDate = pd.to_datetime(real_volatility_startDate)\n",
    "    real_volatility_endDate = pd.to_datetime(real_volatility_endDate)\n",
    "\n",
    "    # Correct way to filter using & operator and parentheses\n",
    "    real_volatility_filtered = real_volatility[(real_volatility.index >= real_volatility_startDate) & (real_volatility.index <= real_volatility_endDate)]\n",
    "    \n",
    "    # filter also the ewma volatility\n",
    "    ewma_volatility = ewma_volatility[(ewma_volatility.index >= real_volatility_startDate) & (ewma_volatility.index <= real_volatility_endDate)]\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 11), sharex=True)\n",
    "\n",
    "    # Plot stock prices\n",
    "    ax1.plot(stock_prices[asset_name], label=f'{asset_name} Price', color='green')\n",
    "    ax1.set_title(f'{asset_name} Stock Prices')\n",
    "    ax1.set_ylabel('Price(dollars)')\n",
    "    ax1.legend(loc='upper left')\n",
    "    \n",
    "    # Plot real and rolling window volatilities\n",
    "    ax2.plot(real_volatility_filtered, label=f'Real {asset_name} Volatility', color='blue')\n",
    "    ax2.plot(ewma_volatility, label=f'EWMA {asset_name} Volatility', color='orange', linestyle='--')\n",
    "    ax2.set_title(f'{asset_name} Volatility: Real vs EWMA')\n",
    "    ax2.set_xlabel('Time(days)')\n",
    "    ax2.set_ylabel('Volatility(%)')\n",
    "    ax2.legend(loc='upper left')\n",
    "\n",
    "    # Set x-axis limits to match the start and end dates\n",
    "    ax1.set_xlim(left=real_volatility_startDate, right=real_volatility_endDate)\n",
    "    ax2.set_xlim(left=real_volatility_startDate, right=real_volatility_endDate)\n",
    "\n",
    "    # Adding vertical lines for specific events\n",
    "    ax1.axvline(pd.Timestamp('2020-02-24'), color='gray', linestyle='--', lw=2)  # COVID start\n",
    "    ax1.axvline(pd.Timestamp('2022-02-24'), color='red', linestyle='--', lw=2)  # Ukraine War start\n",
    "\n",
    "    # Adding vertical lines for specific events\n",
    "    ax2.axvline(pd.Timestamp('2020-02-24'), color='gray', linestyle='--', lw=2)  # COVID start\n",
    "    ax2.axvline(pd.Timestamp('2022-02-24'), color='red', linestyle='--', lw=2)  # Ukraine War start\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prescientDict = {}\n",
    "daily_log_likelihoods = {}\n",
    "daily_regrets = {}\n",
    "\n",
    "# collections for plotting charts about the performance of the EWMA predictor\n",
    "betaValues = []\n",
    "ewmaMeanRegretValues = []\n",
    "ewmaMeanlogLikelihoodValues = []\n",
    "prescientAlreadyPrinted = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covariance Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRESCIENT(GROUND TRUTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CODE IS CALCULATING THE REAL VOLATILITY\n",
    "\n",
    "# prescient is a dictionary that contains the covariance matrix calculated using the ewma formula written inside the paper\n",
    "# the key of the dictionary is the timestamp and the value is the covariance matrix calculated for that day\n",
    "\n",
    "# The prescient predictor will always use the original dataset, so it will be uniformly distributed; this is because the prescient predictor is used to compare the other predictors\n",
    "# and we need to have a measure of the real covariance matrix; so this can't be used with the non-uniformly distributed dataset\n",
    "\n",
    "prescientDict = originalPrescientPredictor(uniformlyDistributedReturns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS THE VISUALIZATION OF THE REAL VOLAITILITIES OF THE 3 ASSETS\n",
    "\n",
    "# now calculates/extract the real volatilities of the 3 assets\n",
    "real_volatilities = {}\n",
    "\n",
    "for date, cov_matrix in prescientDict.items():\n",
    "    volatilities = np.sqrt(np.diag(cov_matrix.values))\n",
    "    real_volatilities[date] = pd.DataFrame(data = volatilities, index = cov_matrix.index, columns = [\"volatility\"])\n",
    "\n",
    "# now real_volatilities is a dictionary that contains the real volatilities of the 3 assets for every day with the same key of the prescientDict dictionary(the timestamp)\n",
    "\n",
    "# now separate the real volatilities of the 3 assets in 3 different dataframes\n",
    "volatility_dict_aapl = {}\n",
    "volatility_dict_ibm = {}\n",
    "volatility_dict_mcd = {}\n",
    "\n",
    "for date, volatilities in real_volatilities.items():\n",
    "    volatility_dict_aapl[date] = volatilities.loc[7][\"volatility\"] # 7 is the PERMCO code of AAPL\n",
    "    volatility_dict_ibm[date] = volatilities.loc[20990][\"volatility\"] # 20990 is the PERMCO code of IBM\n",
    "    volatility_dict_mcd[date] = volatilities.loc[21177][\"volatility\"] # 21177 is the PERMCO code of MCD\n",
    "\n",
    "# Convert the dictionaries to DataFrames for easier manipulation and plotting\n",
    "df_volatility_aapl = pd.DataFrame(list(volatility_dict_aapl.items()), columns=['Date', 'AAPL Volatility'])\n",
    "df_volatility_ibm = pd.DataFrame(list(volatility_dict_ibm.items()), columns=['Date', 'IBM Volatility'])\n",
    "df_volatility_mcd = pd.DataFrame(list(volatility_dict_mcd.items()), columns=['Date', 'MCD Volatility'])\n",
    "\n",
    "# Set the 'Date' column as the index\n",
    "df_volatility_aapl.set_index('Date', inplace=True)\n",
    "df_volatility_ibm.set_index('Date', inplace=True)\n",
    "df_volatility_mcd.set_index('Date', inplace=True)\n",
    "\n",
    "# Plot the real volatilities of the 3 assets\n",
    "plt.figure(figsize=(18, 11))\n",
    "plt.plot(df_volatility_aapl, label='AAPL Volatility')\n",
    "plt.plot(df_volatility_ibm, label='IBM Volatility')\n",
    "plt.plot(df_volatility_mcd, label='MCD Volatility')\n",
    "plt.legend()\n",
    "plt.title(\"Real Volatilities of the 3 assets\")\n",
    "plt.xlabel(\"Time(days)\")\n",
    "plt.ylabel(\"Volatility(%)\")\n",
    "\n",
    "# Adding vertical lines for specific events\n",
    "plt.axvline(pd.Timestamp('2020-02-24'), color='gray', linestyle='--', lw=2)  # COVID start\n",
    "plt.axvline(pd.Timestamp('2022-02-24'), color='orange', linestyle='--', lw=2)  # Ukraine War start\n",
    "\n",
    "# Annotations for the events\n",
    "plt.text(pd.Timestamp('2020-02-24'), plt.ylim()[1], 'COVID', horizontalalignment='center', color='gray')\n",
    "plt.text(pd.Timestamp('2022-02-24'), plt.ylim()[1], 'Ukraine War', horizontalalignment='center', color='orange')\n",
    "\n",
    "# Set x-axis limits to match the start and end dates\n",
    "plt.xlim(left=df_volatility_aapl.index[0], right=df_volatility_aapl.index[-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR THE EWMA PREDICTOR THERE IS NO TRAINING PHASE, THE PREDICTOR HAS BETA AS UNIQUE PARAMETER AND IT IS AN HYPERPARAMETER (0 < BETA < 1). \n",
    "The best value for beta has been found with the grid search method applied in the validation phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Phase for EWMA predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through beta values\n",
    "# ewma_halflife = 100\n",
    "# beta = 2 ** (-1 / ewma_halflife)\n",
    "# beta = 0.1\n",
    "\n",
    "def ewmaValidationPhase(betaValue, startingDate, endingDate, betaIncrement, prescientAlreadyPrinted):\n",
    "    '''\n",
    "    this function is used to perform the validation phase of the EWMA predictor; it's used to find the best beta value for the EWMA predictor.\n",
    "    Grid search is used and the performance of the beta hyperparameter is evaluated using the MSE, log-likelihood and regret metrics.\n",
    "    '''\n",
    "\n",
    "    while betaValue < 1:\n",
    "\n",
    "        ewma_halflife = -np.log(2) / np.log(betaValue)\n",
    "        ewmaDict = dict(_ewma_cov(stocksPercentageChangeReturn, halflife=ewma_halflife))\n",
    "\n",
    "        #\n",
    "        # DEFINE END AND START DATES FOR BACKTESTS\n",
    "        #\n",
    "        \n",
    "        start_date = pd.to_datetime(startingDate, format=\"%Y-%m-%d\")\n",
    "        end_date = pd.to_datetime(endingDate, format=\"%Y-%m-%d\")\n",
    "\n",
    "        names = [\"EWMA\", \"PRESCIENT\"]\n",
    "\n",
    "        #these predictors are all dictionaries where each entry contains a Pandas DataFrame representing a covariance matrix of returns at each timestamp.  \n",
    "        predictors_temp = [ewmaDict, prescientDict]\n",
    "        predictors = [] # so this is a list of dictionaries\n",
    "\n",
    "        for predictor in predictors_temp:\n",
    "            predictors.append({t: predictor[t] for t in predictor.keys() if t >= start_date and t <= end_date})\n",
    "\n",
    "        #\n",
    "        # LOG-LIKELIHOODS\n",
    "        #\n",
    "\n",
    "        '''\n",
    "            this dictionary has a shape like this:\n",
    "            {\n",
    "                RW: pd.Series(log_likelihood(returns_temp, Sigmas_temp), index=times),\n",
    "                EWMA: pd.Series(log_likelihood(returns_temp, Sigmas_temp), index=times),\n",
    "                MGARCH: pd.Series(log_likelihood(returns_temp, Sigmas_temp), index=times),\n",
    "                PRESCIENT: pd.Series(log_likelihood(returns_temp, Sigmas_temp), index=times),\n",
    "            }\n",
    "\n",
    "            where each pd.series is a series of log-likelihoods for each timestamp: so there is the log-likelihood value for each timestamp\n",
    "        '''\n",
    "\n",
    "        for i, predictorDict in enumerate(predictors):\n",
    "\n",
    "            # if the predictor is the prescient predictor, i have to use the uniformly distributed dataset\n",
    "            if names[i] == \"PRESCIENT\":\n",
    "                returns_temp = uniformlyDistributedReturns.loc[pd.Series(predictorDict).index].values[1:]\n",
    "            \n",
    "            else:\n",
    "                returns_temp = stocksPercentageChangeReturn.loc[pd.Series(predictorDict).index].values[1:]\n",
    "\n",
    "            times = pd.Series(predictorDict).index[1:]\n",
    "            Sigmas_temp = np.stack([predictorDict[t].values for t in predictorDict.keys()])[:-1]       \n",
    "            daily_log_likelihoods[names[i]] = pd.Series(log_likelihood(returns_temp, Sigmas_temp), index=times)\n",
    "\n",
    "\n",
    "        #\n",
    "        # REGRETS\n",
    "        #\n",
    "\n",
    "        for name in daily_log_likelihoods:\n",
    "            daily_regrets[name] =  daily_log_likelihoods[\"PRESCIENT\"] - daily_log_likelihoods[name]\n",
    "            \n",
    "        for name in daily_regrets:\n",
    "            if name != \"PRESCIENT\":\n",
    "\n",
    "                #Each data point in the regret series now represents the average regret for a respective quarter. If the original series spans multiple years, then the number of data points in regret will be the number of quarters in that time frame.\n",
    "                quarterly_regrets = daily_regrets[name].resample(\"Q\").mean() #it resamples the regret Series to a quarterly frequency, This gives the average regret for each quarter rather than daily regret values  \n",
    "                # so the regret variable is a series of average regret for each quarter\n",
    "                \n",
    "                regretMetrics = (np.mean(quarterly_regrets).round(1), np.std(quarterly_regrets).round(1), np.max(quarterly_regrets).round(1))\n",
    "                # the round(1) function to each of these metrics, which rounds the result to one decimal place,\n",
    "\n",
    "                # save the regret mean values to plot a chart\n",
    "                ewmaMeanRegretValues.append(regretMetrics[0])\n",
    "\n",
    "\n",
    "        # copy the log-likelihoods dictionary\n",
    "        daily_log_likelihoods_copy = daily_log_likelihoods.copy()\n",
    "\n",
    "        # do the same thing for log-likelihoods dictionary\n",
    "        for name in daily_log_likelihoods_copy:\n",
    "            quarterly_logLikelihood = daily_log_likelihoods_copy[name].resample(\"Q\").mean()\n",
    "            logLikelihoodMetrics = (np.mean(quarterly_logLikelihood).round(1), np.std(quarterly_logLikelihood).round(1), np.max(quarterly_logLikelihood).round(1))\n",
    "\n",
    "            if name != \"PRESCIENT\":\n",
    "\n",
    "                # save the loglikelihood mean values to plot a chart\n",
    "                ewmaMeanlogLikelihoodValues.append(logLikelihoodMetrics[0])\n",
    "                \n",
    "            if name == \"PRESCIENT\" and prescientAlreadyPrinted == False:\n",
    "                prescientAlreadyPrinted = True\n",
    "\n",
    "                # save the loglikelihood mean value to plot a chart\n",
    "                prescientMeanlogLikelihoodValue = logLikelihoodMetrics[0]\n",
    "\n",
    "        # save every fundamental value to plot a chart \n",
    "        betaValues.append(betaValue)\n",
    "\n",
    "        # Increment beta\n",
    "        betaValue += betaIncrement\n",
    "\n",
    "    print(\"lenght of ewmaDict: \", len(ewmaDict))\n",
    "    print(\"first timestamp of ewmaDict: \", list(ewmaDict.keys())[0])\n",
    "    print(\"last timestamp of ewmaDict: \", list(ewmaDict.keys())[-1])\n",
    "\n",
    "    # return the fundamental values to plot a chart\n",
    "    return betaValues, ewmaMeanRegretValues, ewmaMeanlogLikelihoodValues, prescientMeanlogLikelihoodValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used to plot the performance of the ewma predictor in terms of regret and log-likelihood\n",
    "\n",
    "def plotLogLikelihoodPerformanceEWMA(betaValues, ewmaMeanlogLikelihoodValues, prescientMeanlogLikelihoodValue):\n",
    "    '''\n",
    "    plotting the results of the grid search expressed in terms of regret\n",
    "    '''\n",
    "\n",
    "    betaMaxValuesLogLikelihood = [] # this list will contain the beta values that have the max loglikelihood value\n",
    "\n",
    "    # plot the chart of the mean loglikelihood values\n",
    "    plt.figure()\n",
    "    plt.plot(betaValues, ewmaMeanlogLikelihoodValues)\n",
    "    plt.xlabel(\"Beta values\")\n",
    "    plt.ylabel(\"Mean loglikelihood values\")\n",
    "    plt.title(\"Mean loglikelihood values for different beta values\")\n",
    "\n",
    "    # show the prescient predictor loglikelihood value\n",
    "    plt.axhline(y=prescientMeanlogLikelihoodValue, color='r', linestyle='-')\n",
    "    plt.legend([\"EWMA\", \"PRESCIENT\"])\n",
    "\n",
    "    for j in range(len(ewmaMeanlogLikelihoodValues)):\n",
    "        if ewmaMeanlogLikelihoodValues[j] == max(ewmaMeanlogLikelihoodValues):\n",
    "            betaMaxValuesLogLikelihood.append(betaValues[j])\n",
    "\n",
    "    # these points show the interval of beta values that have the max loglikelihood value\n",
    "    highlightPoint1LogLikelihood = betaMaxValuesLogLikelihood[0]\n",
    "    plt.scatter(highlightPoint1LogLikelihood, max(ewmaMeanlogLikelihoodValues), color='r')\n",
    "    #plt.text(highlightPoint1LogLikelihood, max(ewmaMeanlogLikelihoodValues), f' Beta: {highlightPoint1LogLikelihood:.4f}\\n Loglikelihood: {max(ewmaMeanlogLikelihoodValues):.4f}',\n",
    "            #fontsize=9, color='red', ha='center', va='bottom')\n",
    "\n",
    "    highlightPoint2LogLikelihood = betaMaxValuesLogLikelihood[-1]\n",
    "    plt.scatter(highlightPoint2LogLikelihood, max(ewmaMeanlogLikelihoodValues), color='r')\n",
    "    #plt.text(highlightPoint2LogLikelihood, max(ewmaMeanlogLikelihoodValues), f' Beta: {highlightPoint2LogLikelihood:.4f}\\n Loglikelihood: {max(ewmaMeanlogLikelihoodValues):.4f}',\n",
    "            #fontsize=9, color='red', ha='center', va='bottom')\n",
    "\n",
    "    # find the y value coordinate corresponding to the highlightPoint1LogLikelihood and highlightPoint2LogLikelihood\n",
    "    highlightPoint1LogLikelihoodIndex = betaValues.index(highlightPoint1LogLikelihood)\n",
    "    highlightPoint1LogLikelihoodY = ewmaMeanlogLikelihoodValues[highlightPoint1LogLikelihoodIndex]\n",
    "\n",
    "    highlightPoint2LogLikelihoodIndex = betaValues.index(highlightPoint2LogLikelihood)\n",
    "    highlightPoint2LogLikelihoodY = ewmaMeanlogLikelihoodValues[highlightPoint2LogLikelihoodIndex]\n",
    "\n",
    "    print(\"highlightPoint1LogLikelihoodX: \" + str(highlightPoint1LogLikelihood))\n",
    "    print(\"highlightPoint1LogLikelihoodY: \" + str(highlightPoint1LogLikelihoodY))\n",
    "\n",
    "    print(\"highlightPoint2LogLikelihoodX: \" + str(highlightPoint2LogLikelihood))\n",
    "    print(\"highlightPoint2LogLikelihoodY: \" + str(highlightPoint2LogLikelihoodY))\n",
    "\n",
    "    # set the x-axis limits \n",
    "    plt.xlim(left = betaValues[0], right = betaValues[-1])\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plotRegretperformanceEWMA(betaValues, ewmaMeanRegretValues):\n",
    "    '''\n",
    "    plotting the results of the grid search expressed in terms of regret\n",
    "    '''\n",
    "\n",
    "    betaMinValuesRegret = [] # this list will contain the beta values that have the minimum regret value\n",
    "\n",
    "    # plot the chart of the mean regret values\n",
    "    plt.figure()\n",
    "    plt.plot(betaValues, ewmaMeanRegretValues)\n",
    "    plt.xlabel(\"Beta values\")\n",
    "    plt.ylabel(\"Mean regret values\")\n",
    "    plt.title(\"Mean regret values for different beta values\")\n",
    "\n",
    "    # find the minimum value of the mean regret values\n",
    "    for i in range(len(ewmaMeanRegretValues)):\n",
    "        if ewmaMeanRegretValues[i] == min(ewmaMeanRegretValues):\n",
    "            betaMinValuesRegret.append(betaValues[i])\n",
    "\n",
    "    # these points show the interval of beta values that have the minimum regret value\n",
    "    highlightPoint1 = betaMinValuesRegret[0]\n",
    "    plt.scatter(highlightPoint1, min(ewmaMeanRegretValues), color='r')\n",
    "    #plt.text(highlightPoint1, min(ewmaMeanRegretValues), f' Beta: {highlightPoint1:.4f}\\n Regret: {min(ewmaMeanRegretValues):.4f}',\n",
    "            #fontsize=9, color='red', ha='center', va='bottom')\n",
    "\n",
    "    highlightPoint2 = betaMinValuesRegret[-1]\n",
    "    plt.scatter(highlightPoint2, min(ewmaMeanRegretValues), color='r')\n",
    "    #plt.text(highlightPoint2, min(ewmaMeanRegretValues), f' Beta: {highlightPoint2:.4f}\\n Regret: {min(ewmaMeanRegretValues):.4f}',\n",
    "            #fontsize=9, color='red', ha='center', va='bottom')\n",
    "\n",
    "    # find the y value coordinate corresponding to the highlightPoint1 and highlightPoint2\n",
    "    highlightPoint1Index = betaValues.index(highlightPoint1)\n",
    "    highlightPoint1Y = ewmaMeanRegretValues[highlightPoint1Index]\n",
    "\n",
    "    highlightPoint2Index = betaValues.index(highlightPoint2)\n",
    "    highlightPoint2Y = ewmaMeanRegretValues[highlightPoint2Index]\n",
    "    \n",
    "    print(\"highlightPoint1X: \" + str(highlightPoint1))\n",
    "    print(\"highlightPoint1Y: \" + str(highlightPoint1Y))\n",
    "    \n",
    "    print(\"highlightPoint2X: \" + str(highlightPoint2))\n",
    "    print(\"highlightPoint2Y: \" + str(highlightPoint2Y))\n",
    "\n",
    "    # set the x-axis limits \n",
    "    plt.xlim(left = betaValues[0], right = betaValues[-1])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPerformanceEWMA(betaValues, ewmaMeanlogLikelihoodValues, prescientMeanlogLikelihoodValue, ewmaMeanRegretValues):\n",
    "    '''\n",
    "    plotting the results of the grid search expressed in terms of loglikelihood and regret on a single chart\n",
    "    '''\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot the mean log-likelihood values for EWMA\n",
    "    color = 'tab:blue'\n",
    "    ax1.set_xlabel('Beta values')\n",
    "    ax1.set_ylabel('Mean log-likelihood', color=color)\n",
    "    ax1.plot(betaValues, ewmaMeanlogLikelihoodValues, color=color, label='Loglikelihood EWMA')\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    # Plot the loglikelihood value of the prescient predictor\n",
    "    ax1.axhline(y=prescientMeanlogLikelihoodValue, color='tab:green', linestyle='-', label='Loglikelihood PRESCIENT')\n",
    "\n",
    "    # Highlight the maximum log-likelihood points\n",
    "    max_log_likelihood = max(ewmaMeanlogLikelihoodValues)\n",
    "    max_points = [beta for beta, value in zip(betaValues, ewmaMeanlogLikelihoodValues) if value == max_log_likelihood]\n",
    "\n",
    "    # take just the first and last element of the list\n",
    "    max_points = [max_points[0], max_points[-1]]\n",
    "\n",
    "    # scatter the points by writing the beta value and the loglikelihood value on the chart\n",
    "    for point in max_points:\n",
    "        ax1.scatter(point, max_log_likelihood, color='green')\n",
    "        plt.text(point, max_log_likelihood, f' x: {point:.3f}\\n y: {max_log_likelihood:.3f}', fontsize=9, color='green', ha='center', va='bottom')\n",
    "\n",
    "    # Add a second y-axis for the regret values\n",
    "    ax2 = ax1.twinx()  \n",
    "    color = 'tab:red'\n",
    "    ax2.set_ylabel('Mean regret', color=color)  \n",
    "    ax2.plot(betaValues, ewmaMeanRegretValues, color=color, label='Regret EWMA')\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    # Highlight the minimum regret points\n",
    "    min_regret = min(ewmaMeanRegretValues)\n",
    "    min_points = [beta for beta, value in zip(betaValues, ewmaMeanRegretValues) if value == min_regret]\n",
    "\n",
    "    # take just the first and last element of the list\n",
    "    min_points = [min_points[0], min_points[-1]]\n",
    "\n",
    "    # scatter the points by writing the beta value and the regret value on the chart\n",
    "    for point in min_points:\n",
    "        ax2.scatter(point, min_regret, color='red')\n",
    "        plt.text(point, min_regret, f' x: {point:.3f}\\n y: {min_regret:.3f}', fontsize=9, color='red', ha='center', va='bottom')\n",
    "\n",
    "    print(\"max_points: \" + str(max_points))\n",
    "    print(\"min_points: \" + str(min_points))\n",
    "\n",
    "    # Create the legend, which combines both axes\n",
    "    lines, labels = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax2.legend(lines + lines2, labels + labels2, loc='center')\n",
    "\n",
    "    # Add title\n",
    "    plt.title(\"Performance of EWMA for different beta values\")\n",
    "\n",
    "    # Set the x-axis limits\n",
    "    ax1.set_xlim(left=betaValues[0], right=betaValues[-1])\n",
    "\n",
    "    fig.tight_layout()  # to ensure the right y-label is not slightly clipped\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first of all define the starting and ending date for the validation phase: take the first and the last date of the validation dataset\n",
    "startingValidationDate = validationDataWithPercentageChange.index[0].strftime(\"%Y-%m-%d\")\n",
    "endingValidationDate = validationDataWithPercentageChange.index[-1].strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# first run for grid search -> this is a general run to cover the entire range of beta values\n",
    "betaValues, ewmaMeanRegretValues, ewmaMeanlogLikelihoodValues, prescientMeanlogLikelihoodValue = ewmaValidationPhase(0.1, startingValidationDate, endingValidationDate, 0.01, prescientAlreadyPrinted)\n",
    "\n",
    "# plot the performance of the EWMA predictor in terms of loglikelihood\n",
    "plotLogLikelihoodPerformanceEWMA(betaValues, ewmaMeanlogLikelihoodValues, prescientMeanlogLikelihoodValue)\n",
    "\n",
    "# plot the performance of the EWMA predictor in terms of regret\n",
    "plotRegretperformanceEWMA(betaValues, ewmaMeanRegretValues)\n",
    "\n",
    "plotPerformanceEWMA(betaValues, ewmaMeanlogLikelihoodValues, prescientMeanlogLikelihoodValue, ewmaMeanRegretValues)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the chart is evident that the model has the best performance with 0.9 < beta < 1; so now i will do the zoom in this range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to go faster i skip the validation part(the correct memoru value parameter has been already found)\n",
    "\n",
    "\n",
    "'''\n",
    "# clear the lists to make another run of the grid search\n",
    "betaValues.clear()\n",
    "ewmaMeanRegretValues.clear()\n",
    "ewmaMeanlogLikelihoodValues.clear()\n",
    "prescientMeanlogLikelihoodValue = 0\n",
    "\n",
    "# this is a specific run to find the best beta value (i will search in the range 0.9 -> 1 with a step of 0.001)\n",
    "betaValues, ewmaMeanRegretValues, ewmaMeanlogLikelihoodValues, prescientMeanlogLikelihoodValue = ewmaValidationPhase(0.9, startingValidationDate, endingValidationDate, 0.001, prescientAlreadyPrinted)\n",
    "\n",
    "# plot the performance of the EWMA predictor in terms of loglikelihood\n",
    "plotLogLikelihoodPerformanceEWMA(betaValues, ewmaMeanlogLikelihoodValues, prescientMeanlogLikelihoodValue)\n",
    "\n",
    "# plot the performance of the EWMA predictor in terms of regret\n",
    "plotRegretperformanceEWMA(betaValues, ewmaMeanRegretValues)\n",
    "\n",
    "plotPerformanceEWMA(betaValues, ewmaMeanlogLikelihoodValues, prescientMeanlogLikelihoodValue, ewmaMeanRegretValues)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# print the log likelihood value and regret value for beta = 0.97\n",
    "Beta = 0.9870000000000001\n",
    "ewma_halflife = -np.log(2) / np.log(Beta)\n",
    "\n",
    "print(\"betavalues: \" + str(betaValues))\n",
    "\n",
    "print(\"beta: \" + str(Beta))\n",
    "print(\"ewma_halflife: \" + str(ewma_halflife))\n",
    "print(\"log likelihood: \" + str(ewmaMeanlogLikelihoodValues[betaValues.index(Beta)]))\n",
    "print(\"regret: \" + str(ewmaMeanRegretValues[betaValues.index(Beta)]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# example of behaviour with a bad beta value\n",
    "prescientAlreadyPrinted = False\n",
    "startingvalidationDate = validationDataWithPercentageChange.index[0].strftime(\"%Y-%m-%d\")\n",
    "endingvalidationDate = validationDataWithPercentageChange.index[-1].strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# select the best beta value for the EWMA predictor (the one found in the previous step)\n",
    "beta = 0.1\n",
    "\n",
    "ewma_halflife = -np.log(2) / np.log(beta)\n",
    "\n",
    "# now i will use the best beta value to perform the test phase\n",
    "\n",
    "# now i want to print the repective value of beta: the beta is the value of the decay factor used in the ewma formula\n",
    "print(\"ewma_halflife used: \" + str(ewma_halflife) + \"\\n\")\n",
    "\n",
    "# ewma is a dictionary that contains the covariance matrix calculated using the ewma formula written inside the paper\n",
    "# the key of the dictionary is the timestamp and the value is the covariance matrix calculated for that day\n",
    "ewmaDict = dict(_ewma_cov(validationDataWithPercentageChange, ewma_halflife))\n",
    "\n",
    "ewma_volatilities = {}\n",
    "\n",
    "for date, cov_matrix in ewmaDict.items():\n",
    "    volatilities = np.sqrt(np.diag(cov_matrix.values))\n",
    "    ewma_volatilities[date] = pd.DataFrame(data = volatilities, index = cov_matrix.index, columns = [\"volatility\"])\n",
    "\n",
    "# now ewma_volatilities is a dictionary that contains the real volatilities of the 3 assets for every day with the same key of the ewmaDict dictionary(the timestamp)\n",
    "\n",
    "# now filter the ewma volatilities between the start and end date\n",
    "real_volatility_startDate = pd.to_datetime(startingvalidationDate)\n",
    "real_volatility_endDate = pd.to_datetime(endingvalidationDate)\n",
    "\n",
    "# filter the dictionary\n",
    "ewma_volatilities = {k: v for k, v in ewma_volatilities.items() if k >= real_volatility_startDate and k <= real_volatility_endDate}\n",
    "    \n",
    "# now separate the real volatilities of the 3 assets in 3 different dataframes\n",
    "ewma_volatility_dict_aapl = {}\n",
    "ewma_volatility_dict_ibm = {}\n",
    "ewma_volatility_dict_mcd = {}\n",
    "\n",
    "for date, volatilities in ewma_volatilities.items():\n",
    "    ewma_volatility_dict_aapl[date] = volatilities.loc[7][\"volatility\"] # 7 is the PERMCO code of AAPL\n",
    "    ewma_volatility_dict_ibm[date] = volatilities.loc[20990][\"volatility\"] # 20990 is the PERMCO code of IBM\n",
    "    ewma_volatility_dict_mcd[date] = volatilities.loc[21177][\"volatility\"] # 21177 is the PERMCO code of MCD\n",
    "\n",
    "# Convert the dictionaries to DataFrames for easier manipulation and plotting\n",
    "df_ewma_volatility_aapl = pd.DataFrame(list(ewma_volatility_dict_aapl.items()), columns=['Date', 'AAPL Volatility'])\n",
    "df_ewma_volatility_ibm = pd.DataFrame(list(ewma_volatility_dict_ibm.items()), columns=['Date', 'IBM Volatility'])\n",
    "df_ewma_volatility_mcd = pd.DataFrame(list(ewma_volatility_dict_mcd.items()), columns=['Date', 'MCD Volatility'])\n",
    "\n",
    "# Set the 'Date' column as the index\n",
    "df_ewma_volatility_aapl.set_index('Date', inplace=True)\n",
    "df_ewma_volatility_ibm.set_index('Date', inplace=True)\n",
    "df_ewma_volatility_mcd.set_index('Date', inplace=True)\n",
    "\n",
    "# Plot the real volatilities of the 3 assets\n",
    "plt.figure(figsize=(18, 11))\n",
    "plt.plot(df_ewma_volatility_aapl, label='AAPL Volatility')\n",
    "plt.plot(df_ewma_volatility_ibm, label='IBM Volatility')\n",
    "plt.plot(df_ewma_volatility_mcd, label='MCD Volatility')\n",
    "plt.legend()\n",
    "plt.title(\"Volatilities of the 3 assets calculated using the ewma\")\n",
    "plt.xlabel(\"Time(days)\")\n",
    "plt.ylabel(\"Volatility(%)\")\n",
    "\n",
    "# Adding vertical lines for specific events\n",
    "plt.axvline(pd.Timestamp('2020-02-24'), color='gray', linestyle='--', lw=2)  # COVID start\n",
    "plt.axvline(pd.Timestamp('2022-02-24'), color='orange', linestyle='--', lw=2)  # Ukraine War start\n",
    "\n",
    "# Annotations for the events\n",
    "#plt.text(pd.Timestamp('2020-02-24'), plt.ylim()[1], 'COVID', horizontalalignment='center', color='gray')\n",
    "plt.text(pd.Timestamp('2022-02-24'), plt.ylim()[1], 'Ukraine War', horizontalalignment='center', color='orange')\n",
    "\n",
    "# set x-axis limits to match the start and end dates\n",
    "plt.xlim(left=df_ewma_volatility_aapl.index[0], right=df_ewma_volatility_aapl.index[-1])\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# HERE THERE IS THE VOLATILITY ANALYSIS OF THE EWMA PREDICTOR COMPARED TO THE REAL VOLATILITY\n",
    "startDateFilter = validationDataWithPrices.index[0]\n",
    "endDateFilter = validationDataWithPrices.index[-1]\n",
    "\n",
    "plot_prices_volatilities_for_ewma(validationDataWithPrices, df_volatility_aapl['AAPL Volatility'], startDateFilter, endDateFilter, df_ewma_volatility_aapl['AAPL Volatility'], 'AAPL')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Phase for EWMA predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this test phase i will use the best value for beta found in the validation phase to see the performance of the model on the test set and i will plot some charts to compare the volatility predicted by the model with the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the date for the test phase\n",
    "prescientAlreadyPrinted = False\n",
    "startingTestDate = testDataWithPercentageChange.index[0].strftime(\"%Y-%m-%d\")\n",
    "endingTestDate = testDataWithPercentageChange.index[-1].strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# select the best beta value for the EWMA predictor (the one found in the previous step)\n",
    "beta = predictorsConfiguration[\"EWMA_beta\"]\n",
    "ewma_halflife = -np.log(2) / np.log(beta)\n",
    "\n",
    "# now i will use the best beta value to perform the test phase\n",
    "\n",
    "# now i want to print the repective value of beta: the beta is the value of the decay factor used in the ewma formula\n",
    "print(\"ewma_halflife used: \" + str(ewma_halflife) + \"\\n\")\n",
    "\n",
    "# ewma is a dictionary that contains the covariance matrix calculated using the ewma formula written inside the paper\n",
    "# the key of the dictionary is the timestamp and the value is the covariance matrix calculated for that day\n",
    "ewmaDict = dict(_ewma_cov(testDataWithPercentageChange, ewma_halflife))\n",
    "\n",
    "ewma_volatilities = {}\n",
    "\n",
    "for date, cov_matrix in ewmaDict.items():\n",
    "    volatilities = np.sqrt(np.diag(cov_matrix.values))\n",
    "    ewma_volatilities[date] = pd.DataFrame(data = volatilities, index = cov_matrix.index, columns = [\"volatility\"])\n",
    "\n",
    "# now ewma_volatilities is a dictionary that contains the real volatilities of the 3 assets for every day with the same key of the ewmaDict dictionary(the timestamp)\n",
    "\n",
    "# now filter the ewma volatilities between the start and end date\n",
    "real_volatility_startDate = pd.to_datetime(startingTestDate)\n",
    "real_volatility_endDate = pd.to_datetime(endingTestDate)\n",
    "\n",
    "# filter the dictionary\n",
    "ewma_volatilities = {k: v for k, v in ewma_volatilities.items() if k >= real_volatility_startDate and k <= real_volatility_endDate}\n",
    "    \n",
    "# now separate the real volatilities of the 3 assets in 3 different dataframes\n",
    "ewma_volatility_dict_aapl = {}\n",
    "ewma_volatility_dict_ibm = {}\n",
    "ewma_volatility_dict_mcd = {}\n",
    "\n",
    "for date, volatilities in ewma_volatilities.items():\n",
    "    ewma_volatility_dict_aapl[date] = volatilities.loc[7][\"volatility\"] # 7 is the PERMCO code of AAPL\n",
    "    ewma_volatility_dict_ibm[date] = volatilities.loc[20990][\"volatility\"] # 20990 is the PERMCO code of IBM\n",
    "    ewma_volatility_dict_mcd[date] = volatilities.loc[21177][\"volatility\"] # 21177 is the PERMCO code of MCD\n",
    "\n",
    "# Convert the dictionaries to DataFrames for easier manipulation and plotting\n",
    "df_ewma_volatility_aapl = pd.DataFrame(list(ewma_volatility_dict_aapl.items()), columns=['Date', 'AAPL Volatility'])\n",
    "df_ewma_volatility_ibm = pd.DataFrame(list(ewma_volatility_dict_ibm.items()), columns=['Date', 'IBM Volatility'])\n",
    "df_ewma_volatility_mcd = pd.DataFrame(list(ewma_volatility_dict_mcd.items()), columns=['Date', 'MCD Volatility'])\n",
    "\n",
    "# Set the 'Date' column as the index\n",
    "df_ewma_volatility_aapl.set_index('Date', inplace=True)\n",
    "df_ewma_volatility_ibm.set_index('Date', inplace=True)\n",
    "df_ewma_volatility_mcd.set_index('Date', inplace=True)\n",
    "\n",
    "# Plot the real volatilities of the 3 assets\n",
    "plt.figure(figsize=(18, 11))\n",
    "plt.plot(df_ewma_volatility_aapl, label='AAPL Volatility')\n",
    "plt.plot(df_ewma_volatility_ibm, label='IBM Volatility')\n",
    "plt.plot(df_ewma_volatility_mcd, label='MCD Volatility')\n",
    "plt.legend()\n",
    "plt.title(\"Volatilities of the 3 assets calculated using the ewma\")\n",
    "plt.xlabel(\"Time(days)\")\n",
    "plt.ylabel(\"Volatility(%)\")\n",
    "\n",
    "# Adding vertical lines for specific events\n",
    "plt.axvline(pd.Timestamp('2020-02-24'), color='gray', linestyle='--', lw=2)  # COVID start\n",
    "plt.axvline(pd.Timestamp('2022-02-24'), color='orange', linestyle='--', lw=2)  # Ukraine War start\n",
    "\n",
    "# set x-axis limits to match the start and end dates\n",
    "plt.xlim(left=df_ewma_volatility_aapl.index[0], right=df_ewma_volatility_aapl.index[-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE THERE IS THE VOLATILITY ANALYSIS OF THE EWMA PREDICTOR COMPARED TO THE REAL VOLATILITY\n",
    "startDateFilter = testDataWithPrices.index[0]\n",
    "endDateFilter = testDataWithPrices.index[-1]\n",
    "\n",
    "plot_prices_volatilities_for_ewma(testDataWithPrices, df_volatility_aapl['AAPL Volatility'], startDateFilter, endDateFilter, df_ewma_volatility_aapl['AAPL Volatility'], 'AAPL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prices_volatilities_for_ewma(testDataWithPrices, df_volatility_ibm['IBM Volatility'], startDateFilter, endDateFilter, df_ewma_volatility_ibm['IBM Volatility'], 'IBM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prices_volatilities_for_ewma(testDataWithPrices, df_volatility_mcd['MCD Volatility'], startDateFilter, endDateFilter, df_ewma_volatility_mcd['MCD Volatility'], 'MCD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW I DO THE LAST THING; THE COMPARISON BETWEEN THE EWMA PREDICTOR AND THE PRESCIENT PREDICTOR IN TERMS OF \n",
    "# LOGLIKELIHOOD, LOGLIKELIHOOD REGRET AND MSE\n",
    "\n",
    "# first of all define the starting and ending date for the test phase: take the first and the last date of the test dataset\n",
    "\n",
    "startingTestDate = testDataWithPercentageChange.index[0].strftime(\"%Y-%m-%d\")\n",
    "endingTestDate = testDataWithPercentageChange.index[-1].strftime(\"%Y-%m-%d\")\n",
    "\n",
    "start_date = pd.to_datetime(startingTestDate, format=\"%Y-%m-%d\")\n",
    "end_date = pd.to_datetime(endingTestDate, format=\"%Y-%m-%d\")\n",
    "\n",
    "names = [\"EWMA\", \"PRESCIENT\"]\n",
    "\n",
    "#these predictors are all dictionaries where each entry contains a Pandas DataFrame representing a covariance matrix of returns at each timestamp.  \n",
    "predictors_temp = [ewmaDict, prescientDict]\n",
    "predictors = [] # so this is a list of dictionaries\n",
    "\n",
    "for predictor in predictors_temp:\n",
    "    predictors.append({t: predictor[t] for t in predictor.keys() if t >= start_date and t <= end_date})\n",
    "\n",
    "\n",
    "ewmaDictionary = predictors[0]\n",
    "ewmaDictionary = {k: ewmaDictionary[k] for k in list(ewmaDictionary)[19:]}\n",
    "predictors[0] = ewmaDictionary\n",
    "\n",
    "# now remove the first 19 entries from the predictor 1(prescient dict)\n",
    "prescientDictionary = predictors[1]\n",
    "\n",
    "# now remove the first 19 entries from the prescient dict\n",
    "prescientDictionary = {k: prescientDictionary[k] for k in list(prescientDictionary)[19:]}\n",
    "predictors[1] = prescientDictionary\n",
    "\n",
    "print(\"size of the first predictor: \" + str(len(predictors[0])))\n",
    "print(\"size of the second predictor: \" + str(len(predictors[1])))\n",
    "\n",
    "\n",
    "# make an assert to check if the length of the two predictors is the same\n",
    "assert len(predictors[0]) == len(predictors[1])\n",
    "\n",
    "# make an assert to check if the timestamps of the two predictors are the same\n",
    "assert predictors[0].keys() == predictors[1].keys()\n",
    "\n",
    "# print the first timestamp of the two predictors\n",
    "print(\"first timestamp of the first predictor: \" + str(list(predictors[0].keys())[0]))\n",
    "print(\"first timestamp of the second predictor: \" + str(list(predictors[1].keys())[0]))\n",
    "\n",
    "# if we are here, it means that the two predictors have the same length and the same timestamps so i can measure the performance of the two predictors\n",
    "\n",
    "\n",
    "#\n",
    "# LOG-LIKELIHOODS\n",
    "#\n",
    "\n",
    "'''\n",
    "    this dictionary has a shape like this:\n",
    "    {\n",
    "        RW: pd.Series(log_likelihood(returns_temp, Sigmas_temp), index=times),\n",
    "        EWMA: pd.Series(log_likelihood(returns_temp, Sigmas_temp), index=times),\n",
    "        ewma: pd.Series(log_likelihood(returns_temp, Sigmas_temp), index=times),\n",
    "        PRESCIENT: pd.Series(log_likelihood(returns_temp, Sigmas_temp), index=times),\n",
    "    }\n",
    "\n",
    "    where each pd.series is a series of log-likelihoods for each timestamp: so there is the log-likelihood value for each timestamp\n",
    "'''\n",
    "\n",
    "log_likelihoods = {}\n",
    "for i, predictorDict in enumerate(predictors):\n",
    "\n",
    "    # if the predictor is the prescient predictor, i have to use the uniformly distributed dataset\n",
    "    if names[i] == \"PRESCIENT\":\n",
    "        returns_temp = uniformlyDistributedReturns.loc[pd.Series(predictorDict).index].values[1:]\n",
    "    \n",
    "    else:\n",
    "        returns_temp = stocksPercentageChangeReturn.loc[pd.Series(predictorDict).index].values[1:]\n",
    "\n",
    "    times = pd.Series(predictorDict).index[1:]\n",
    "    Sigmas_temp = np.stack([predictorDict[t].values for t in predictorDict.keys()])[:-1]       \n",
    "    log_likelihoods[names[i]] = pd.Series(log_likelihood(returns_temp, Sigmas_temp), index=times)\n",
    "\n",
    "\n",
    "# Iterate through each predictor in the log_likelihoods dictionary\n",
    "for name in log_likelihoods.keys():\n",
    "    if name == 'PRESCIENT':\n",
    "        # Resample by quarter, take the mean, and plot with specific color and label\n",
    "        log_likelihoods[name].resample(\"Q\").mean().plot(label=name, c=\"k\")\n",
    "    else:\n",
    "        # Resample by quarter, take the mean, and plot with default settings\n",
    "        log_likelihoods[name].resample(\"Q\").mean().plot(label=name)\n",
    "\n",
    "\n",
    "plt.xlabel('Time(quarter)')  # Set the x-axis label\n",
    "plt.ylabel('Log Likelihood')  # Set the y-axis label\n",
    "plt.title('Quarterly Mean Log Likelihood by Predictor')  # Set the title of the plot\n",
    "plt.legend()  # Show the legend to identify each predictor\n",
    "plt.show()  # Display the plot\n",
    "\n",
    "'''\n",
    "    this dictionary has a shape like this:\n",
    "    {\n",
    "        RW: pd.Series(...),\n",
    "        EWMA: pd.Series(...),\n",
    "        ewma: pd.Series(...),\n",
    "        PRESCIENT: pd.Series(...),\n",
    "    }\n",
    "\n",
    "    where each pd.series is a series of regret for each timestamp: so there is the \n",
    "    regret value (the difference between the log-likelihood of the prescient model and the log-likelihood of the model) for each timestamp\n",
    "'''\n",
    "regrets = {}\n",
    "for name in log_likelihoods:\n",
    "    regrets[name] =  log_likelihoods[\"PRESCIENT\"] - log_likelihoods[name]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "for name in names:\n",
    "    if name == 'PRESCIENT':\n",
    "        pass\n",
    "    else:\n",
    "        regrets[name].resample(\"Q\").mean().plot(label=name)\n",
    "plt.legend(bbox_to_anchor=(1, 1.1), loc='center', ncols=4, labels=names[:-1], scatterpoints=1, markerscale=5);\n",
    "plt.xlabel(\"Time(quarter)\")\n",
    "plt.ylabel(\"Regret\")\n",
    "plt.title(\"Regret\")\n",
    "\n",
    "for name in regrets:\n",
    "    if name != \"PRESCIENT\":\n",
    "\n",
    "        #Each data point in the regret series now represents the average regret for a respective quarter. If the original series spans multiple years, then the number of data points in regret will be the number of quarters in that time frame.\n",
    "        regret = regrets[name].resample(\"Q\").mean() #it resamples the regret Series to a quarterly frequency, This gives the average regret for each quarter rather than daily regret values  \n",
    "        # so the regret variable is a series of average regret for each quarter\n",
    "        \n",
    "        regretMetrics = (np.mean(regret).round(1), np.std(regret).round(1), np.max(regret).round(1))\n",
    "        # the round(1) function to each of these metrics, which rounds the result to one decimal place,\n",
    "\n",
    "        # save the regret mean values to plot a chart\n",
    "        ewmaMeanRegretValues.append(regretMetrics[0])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"meanRegret: {regretMetrics[0]:.3f}\")\n",
    "print(f\"stdRegret: {regretMetrics[1]:.3f}\")\n",
    "print(f\"maxRegret: {regretMetrics[2]:.3f}\")\n",
    "\n",
    "# copy the log-likelihoods dictionary\n",
    "log_likelihoods_copy = log_likelihoods.copy()\n",
    "\n",
    "# do the same thing for log-likelihoods dictionary\n",
    "for name in log_likelihoods_copy:\n",
    "    logLikelihood = log_likelihoods_copy[name].resample(\"Q\").mean()\n",
    "    logLikelihoodMetrics = (np.mean(logLikelihood).round(1), np.std(logLikelihood).round(1), np.max(logLikelihood).round(1))\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(f\"meanLoglikelihood{name}: {logLikelihoodMetrics[0]:.3f}\")\n",
    "    print(f\"stdLoglikelihood{name}: {logLikelihoodMetrics[1]:.3f}\")\n",
    "    print(f\"maxLoglikelihood{name}: {logLikelihoodMetrics[2]:.3f}\")\n",
    "\n",
    "\n",
    "#\n",
    "# RMSEs\n",
    "#\n",
    "\n",
    "print(\"lenght of prescientDict: \", len(prescientDict))\n",
    "print(\"lenght of ewmaDict: \", len(ewmaDict))\n",
    "        \n",
    "for i, predictorDict in enumerate(predictors):\n",
    "    if names[i] != \"PRESCIENT\":\n",
    "        print(\"lenght of predictorDict: \", len(predictorDict))\n",
    "        RMSEs = RMSE(testDataWithPercentageChange, predictorDict, prescientDict, start_date)\n",
    "        print(\"\\n\" + names[i] + \" RMSE\")\n",
    "\n",
    "        # Calculate mean, standard deviation, and max value of the RMSEs\n",
    "        mean_rmse = np.mean(list(RMSEs.values()))\n",
    "        std_rmse = np.std(list(RMSEs.values()))\n",
    "        max_rmse = np.max(list(RMSEs.values()))\n",
    "\n",
    "        print(f\"mean: {mean_rmse:.10f}\")\n",
    "        print(f\"std: {std_rmse:.10f}\")\n",
    "        print(f\"max: {max_rmse:.10f}\")\n",
    "\n",
    "\n",
    "print(\"lenght of rmses: \", len(RMSEs))\n",
    "print(\"values of rmses: \", RMSEs)\n",
    "\n",
    "# Convert Timestamps to strings for plotting\n",
    "timestamps = [ts.strftime('%Y-%m-%d') for ts in RMSEs.keys()]\n",
    "rmse_values = list(RMSEs.values())\n",
    "\n",
    "# Plot the RMSEs with improved formatting\n",
    "plt.figure(figsize=(14, 7))  # Increase the figure size for better readability\n",
    "plt.plot(timestamps, rmse_values, marker='o', linestyle='-', label='EWMA', color='b')\n",
    "\n",
    "# Set the x-axis to only include the dates from the dictionary\n",
    "plt.xticks(timestamps, rotation=45)\n",
    "\n",
    "# Remove the left margin\n",
    "plt.margins(x=0)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Time (Quarter)')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSEs')\n",
    "plt.legend()\n",
    "\n",
    "# Adjust the layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "#\n",
    "# RMSEs for single assets\n",
    "#\n",
    "        \n",
    "# take the first timestamp contained in prescientDict and use it as the start date\n",
    "startDAte = list(prescientDictionary.keys())[0]\n",
    "\n",
    "# filter every volatility dictionary to get only the values that are greater than or equal to the start date\n",
    "volatility_dict_aapl_filtered = {k: v for k, v in volatility_dict_aapl.items() if k >= startDAte}\n",
    "volatility_dict_ibm_filtered = {k: v for k, v in volatility_dict_ibm.items() if k >= startDAte}\n",
    "volatility_dict_mcd_filtered = {k: v for k, v in volatility_dict_mcd.items() if k >= startDAte}\n",
    "\n",
    "volatility_dict_aapl_ewma_filtered = {k: v for k, v in ewma_volatility_dict_aapl.items() if k >= startDAte}\n",
    "volatility_dict_ibm_ewma_filtered = {k: v for k, v in ewma_volatility_dict_ibm.items() if k >= startDAte}\n",
    "volatility_dict_mcd_ewma_filtered = {k: v for k, v in ewma_volatility_dict_mcd.items() if k >= startDAte}\n",
    "\n",
    "\n",
    "print(\"lenght of volatility_dict_aapl: \", len(volatility_dict_aapl_filtered))\n",
    "print(\"lenght of volatility_dict_aaapl_ewma: \", len(volatility_dict_aapl_ewma_filtered))\n",
    "# get the rmse of single assets. i take just aapl, ibm and mcd\n",
    "        \n",
    "RMSEs_aapl_dict = RMSEforSingleVolatility(testDataWithPercentageChange, volatility_dict_aapl_filtered, volatility_dict_aapl_ewma_filtered, start_date)\n",
    "RMSEs_ibm_dict = RMSEforSingleVolatility(testDataWithPercentageChange, volatility_dict_ibm_filtered, volatility_dict_ibm_ewma_filtered, start_date)\n",
    "RMSEs_mcd_dict = RMSEforSingleVolatility(testDataWithPercentageChange, volatility_dict_mcd_filtered, volatility_dict_mcd_ewma_filtered, start_date)\n",
    "\n",
    "print(\"lenght of RMSEs_aapl: \", len(RMSEs_aapl_dict))\n",
    "print(\"values of RMSEs_aapl: \", RMSEs_aapl_dict)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"RMSEs for AAPL\")\n",
    "\n",
    "# Calculate mean, standard deviation, and max value of the RMSEs. the RMSEs are dictionaries whose key is the timestamp and the value is the rmse value\n",
    "mean_rmse_aapl = np.mean(list(RMSEs_aapl_dict.values()))\n",
    "std_rmse_aapl = np.std(list(RMSEs_aapl_dict.values()))\n",
    "max_rmse_aapl = np.max(list(RMSEs_aapl_dict.values()))\n",
    "\n",
    "print(f\"mean: {mean_rmse_aapl:.10f}\")\n",
    "print(f\"std: {std_rmse_aapl:.10f}\")\n",
    "print(f\"max: {max_rmse_aapl:.10f}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"RMSEs for IBM\")\n",
    "\n",
    "# Calculate mean, standard deviation, and max value of the RMSEs. the RMSEs are dictionaries whose key is the timestamp and the value is the rmse value\n",
    "mean_rmse_ibm = np.mean(list(RMSEs_ibm_dict.values()))\n",
    "std_rmse_ibm = np.std(list(RMSEs_ibm_dict.values()))\n",
    "max_rmse_ibm = np.max(list(RMSEs_ibm_dict.values()))\n",
    "\n",
    "print(f\"mean: {mean_rmse_ibm:.10f}\")\n",
    "print(f\"std: {std_rmse_ibm:.10f}\")\n",
    "print(f\"max: {max_rmse_ibm:.10f}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"RMSEs for MCD\")\n",
    "\n",
    "# Calculate mean, standard deviation, and max value of the RMSEs. the RMSEs are dictionaries whose key is the timestamp and the value is the rmse value\n",
    "mean_rmse_mcd = np.mean(list(RMSEs_mcd_dict.values()))\n",
    "std_rmse_mcd = np.std(list(RMSEs_mcd_dict.values()))\n",
    "max_rmse_mcd = np.max(list(RMSEs_mcd_dict.values()))\n",
    "\n",
    "print(f\"mean: {mean_rmse_mcd:.10f}\")\n",
    "print(f\"std: {std_rmse_mcd:.10f}\")\n",
    "print(f\"max: {max_rmse_mcd:.10f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
